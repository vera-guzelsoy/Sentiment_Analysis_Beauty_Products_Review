{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Beauty Products Review-Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Array\n",
    "import numpy as np\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Inspected Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "df2 = pd.read_csv('C:/Users/guzel/Documents/amazon_beauty_products/data_inspected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>rating_class</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A6VPK7X53QNAQ</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If I had to choose only one product to take ca...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2009-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3CHMHGSJSQ02J</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Makes my skin lovely and smooth As a woman nea...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2013-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1V1EP514B5H7Y</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Works well at a reasonable price I've used thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2011-11-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer     product  rating  \\\n",
       "0   A6VPK7X53QNAQ  B0000CC64W     5.0   \n",
       "1  A3CHMHGSJSQ02J  B0000CC64W     5.0   \n",
       "2  A1V1EP514B5H7Y  B0000CC64W     5.0   \n",
       "\n",
       "                                         review_text  pos_feedback  \\\n",
       "0  If I had to choose only one product to take ca...             5   \n",
       "1  Makes my skin lovely and smooth As a woman nea...             2   \n",
       "2  Works well at a reasonable price I've used thi...             0   \n",
       "\n",
       "   neg_feedback rating_class        time  \n",
       "0             0         good  2009-06-18  \n",
       "1             0         good  2013-01-18  \n",
       "2             0         good  2011-11-29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample observations\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "tokenizer = ToktokTokenizer()\n",
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing HTML tags**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a function to remove the HTML tags which typically does not add much value towards understanding and analyzing text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    \n",
    "    \"Removes html tags in the text\"\n",
    "    \n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing accented characters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a function to convert and standardize accented characters/letters into ASCII characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    \n",
    "    \"Removes and standardize accented characters/letters\"\n",
    "    \n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expanding Contractions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a function to convert each contraction to its expanded, orginal form in order to help with text standardization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    \"Convert contractions into their original forms\"\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Special Characters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use simple regular expressions(regexes) to remove special characters and symbols which are usually non-alphanumeric characters or even occasional numeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    \n",
    "    \"Remove special characters/symbols\"\n",
    "    \n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove word affixes to get to the base form of a word, known as root word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash ! the car crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! the car crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing stopwords**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a function to remove stopwords which have little or no significance in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Tokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "# Create stopword list\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# 'no' and 'not' may give us information so those are removed from stop list\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    \n",
    "    \"Remove stopwords in the text except 'no' and 'not'\"\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Text Normalizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the functions which we have written above and also with additional text correction techniques, we will build a text normalizer in order to help us to preproces the new_text document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(doc, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "     \n",
    "    # strip HTML\n",
    "    if html_stripping:\n",
    "        doc = strip_html_tags(doc)\n",
    "            \n",
    "    # remove accented characters\n",
    "    if accented_char_removal:\n",
    "        doc = remove_accented_chars(doc)\n",
    "            \n",
    "    # expand contractions    \n",
    "    if contraction_expansion:\n",
    "        doc = expand_contractions(doc)\n",
    "            \n",
    "    # lowercase the text    \n",
    "    if text_lower_case:\n",
    "        doc = doc.lower()\n",
    "            \n",
    "    # remove extra newlines\n",
    "    doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        \n",
    "    # lemmatize text\n",
    "    if text_lemmatization:\n",
    "        doc = lemmatize_text(doc)\n",
    "            \n",
    "    # remove special characters and\\or digits    \n",
    "    if special_char_removal:\n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "            \n",
    "    # remove extra whitespace\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "        \n",
    "    # remove ' (apostrophe) sign\n",
    "    doc = re.sub(r\"'\", r'', doc)\n",
    "        \n",
    "    # remove stopwords\n",
    "    if stopword_removal:\n",
    "        doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying text normalizer to \"review_text\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for cleaned text \n",
    "df2['clean_text'] = df2['review_text'].map(lambda doc: normalize_corpus(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying tokenizer to create tokens for the clean text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>rating_class</th>\n",
       "      <th>time</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A6VPK7X53QNAQ</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If I had to choose only one product to take ca...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2009-06-18</td>\n",
       "      <td>choose one product take care face rest life wo...</td>\n",
       "      <td>[choose, one, product, take, care, face, rest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3CHMHGSJSQ02J</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Makes my skin lovely and smooth As a woman nea...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>make skin lovely smooth woman near need help g...</td>\n",
       "      <td>[make, skin, lovely, smooth, woman, near, need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1V1EP514B5H7Y</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Works well at a reasonable price I've used thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "      <td>2011-11-29</td>\n",
       "      <td>work well reasonable price use regenerating se...</td>\n",
       "      <td>[work, well, reasonable, price, use, regenerat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1X2LENOF84LCQ</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This does work ladies I have tried so many pro...</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>good</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>work lady try many product totally disappointe...</td>\n",
       "      <td>[work, lady, try, many, product, totally, disa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2PATWWZAXHQYA</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Did not like the feel/texture of this serum I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>2013-12-21</td>\n",
       "      <td>not like feel texture serum love oil olay prim...</td>\n",
       "      <td>[not, like, feel, texture, serum, love, oil, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer     product  rating  \\\n",
       "0   A6VPK7X53QNAQ  B0000CC64W     5.0   \n",
       "1  A3CHMHGSJSQ02J  B0000CC64W     5.0   \n",
       "2  A1V1EP514B5H7Y  B0000CC64W     5.0   \n",
       "3  A1X2LENOF84LCQ  B0000CC64W     4.0   \n",
       "4  A2PATWWZAXHQYA  B0000CC64W     1.0   \n",
       "\n",
       "                                         review_text  pos_feedback  \\\n",
       "0  If I had to choose only one product to take ca...             5   \n",
       "1  Makes my skin lovely and smooth As a woman nea...             2   \n",
       "2  Works well at a reasonable price I've used thi...             0   \n",
       "3  This does work ladies I have tried so many pro...            62   \n",
       "4  Did not like the feel/texture of this serum I ...             1   \n",
       "\n",
       "   neg_feedback rating_class        time  \\\n",
       "0             0         good  2009-06-18   \n",
       "1             0         good  2013-01-18   \n",
       "2             0         good  2011-11-29   \n",
       "3            13         good  2005-04-13   \n",
       "4             0          bad  2013-12-21   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  choose one product take care face rest life wo...   \n",
       "1  make skin lovely smooth woman near need help g...   \n",
       "2  work well reasonable price use regenerating se...   \n",
       "3  work lady try many product totally disappointe...   \n",
       "4  not like feel texture serum love oil olay prim...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [choose, one, product, take, care, face, rest,...  \n",
       "1  [make, skin, lovely, smooth, woman, near, need...  \n",
       "2  [work, well, reasonable, price, use, regenerat...  \n",
       "3  [work, lady, try, many, product, totally, disa...  \n",
       "4  [not, like, feel, texture, serum, love, oil, o...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenizer to create a new column named as tokens which consists of the list of the reviews\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df2[\"tokens\"] = df2[\"clean_text\"].apply(tokenizer.tokenize)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024818 words total, with a vocabulary size of 27739\n",
      "Max review length is (word based) 1090\n",
      "Max review length is (word based) 1\n"
     ]
    }
   ],
   "source": [
    "# Tokens status\n",
    "all_words = [word for tokens in df2[\"tokens\"] for word in tokens]\n",
    "sentence_lengths = [len(tokens) for tokens in df2[\"tokens\"]]\n",
    "vocabulary = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(vocabulary)))\n",
    "print(\"Max review length is (word based) %s\" % max(sentence_lengths))\n",
    "print(\"Max review length is (word based) %s\" % min(sentence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepate the Text Proprocessed dataset to Modeling by selecting required columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the time converting to only year info\n",
    "df2['year'] = pd.DatetimeIndex(df2['time']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "df2 = df2[['customer','product','review_text','rating_class','year','clean_text','tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating_class</th>\n",
       "      <th>year</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A6VPK7X53QNAQ</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>If I had to choose only one product to take ca...</td>\n",
       "      <td>good</td>\n",
       "      <td>2009</td>\n",
       "      <td>choose one product take care face rest life wo...</td>\n",
       "      <td>[choose, one, product, take, care, face, rest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3CHMHGSJSQ02J</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>Makes my skin lovely and smooth As a woman nea...</td>\n",
       "      <td>good</td>\n",
       "      <td>2013</td>\n",
       "      <td>make skin lovely smooth woman near need help g...</td>\n",
       "      <td>[make, skin, lovely, smooth, woman, near, need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1V1EP514B5H7Y</td>\n",
       "      <td>B0000CC64W</td>\n",
       "      <td>Works well at a reasonable price I've used thi...</td>\n",
       "      <td>good</td>\n",
       "      <td>2011</td>\n",
       "      <td>work well reasonable price use regenerating se...</td>\n",
       "      <td>[work, well, reasonable, price, use, regenerat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer     product  \\\n",
       "0   A6VPK7X53QNAQ  B0000CC64W   \n",
       "1  A3CHMHGSJSQ02J  B0000CC64W   \n",
       "2  A1V1EP514B5H7Y  B0000CC64W   \n",
       "\n",
       "                                         review_text rating_class  year  \\\n",
       "0  If I had to choose only one product to take ca...         good  2009   \n",
       "1  Makes my skin lovely and smooth As a woman nea...         good  2013   \n",
       "2  Works well at a reasonable price I've used thi...         good  2011   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  choose one product take care face rest life wo...   \n",
       "1  make skin lovely smooth woman near need help g...   \n",
       "2  work well reasonable price use regenerating se...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [choose, one, product, take, care, face, rest,...  \n",
       "1  [make, skin, lovely, smooth, woman, near, need...  \n",
       "2  [work, well, reasonable, price, use, regenerat...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample observations\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " df2.to_csv('cleaned_dataset.csv', sep = ',', encoding = 'utf-8', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
